{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Modelling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will implement a classification model to predict which patients will get caries in the coming year and which not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/adc-jaimier/PythonTraining/main/Data/Exercise4.csv')\n",
    "X = df[['CLIENT_ID', 'GENDER', 'DATE_OF_BIRTH_YEAR', 'DATE_OF_BIRTH_MONTH',\n",
    "       'DATE_OF_BIRTH_DAY', 'AGE', 'N_PERIODONTAL', 'N_FILLING',\n",
    "       'N_ORAL_HYGIENE', 'N_CHECKS', 'N_YEARS', 'PR_DENTIST', 'DPSI',\n",
    "       'N_FAMILY', 'DIABETES', 'SMOKER']]\n",
    "\n",
    "y = df['Y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first step is to split the data between training and test (out of sample) data. Use scikit learn to split the data, where 80% of the rows will form the training data and the rest will be test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dedicated train and test dataset, we can train a classification model on the data. Use the next block to train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the trained model, we can evaluate how the model performs on out of sample observations. To do this, we can make use of the accuracy. What is the accuracy of your trained model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = \n",
    "print(f'The accuracy of the Logistic Regression is {accuracy:.2f}') \n",
    "# This print statement is a nice way of including variables in the print statement by using {}.\n",
    "# Furthermore, to format floats, we can use the .2f which tells Python to format on 2 decimals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is a very straightforward metric for classification, but not always the best option. Especially when there is an uneven distributions in the classes. Can you think of a reason why? As an alternative, we can use the recall score. Calculate the recall score for your trained logistic regression model. Print the recall rounded up to three decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "recall = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit learn LogisticRegression classifier takes no required arguments when initializing. However, it definitely takes optional arguments as arguments. This include, but are not limited to, for example a penalty parameter, a regularization parameter, or the solver that will be used. To find out which arguments a function takes, always check the documentation. Train a new logistic regression model that takes into account the class imbalance in the target variable. How big is difference in the accuracy, if any? And in the recall? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All performance metrics for classification models can be constructed from the so called confusion matrix, which is an overview of the amount of True Positives (TP), False Positives (FP), False Negatives (FN) and True Negative (TN). Use a scikit learn method to get the confusion matrix for the trained model. Hint: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you also compute the accuracy from the confusion matrix result, using Python code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
